{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vt_qsiTPRhaH"
   },
   "source": [
    "# **Install and Import Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79588,
     "status": "ok",
     "timestamp": 1701585543678,
     "user": {
      "displayName": "Rohan Kumar",
      "userId": "17820626819411478205"
     },
     "user_tz": -330
    },
    "id": "CrjWaM55ReHu",
    "outputId": "08e37a11-5080-4771-ad14-2c8b6c0a9093"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1701586369054,
     "user": {
      "displayName": "Rohan Kumar",
      "userId": "17820626819411478205"
     },
     "user_tz": -330
    },
    "id": "RZewup-5V4L5"
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJU_jcTpRwW_"
   },
   "source": [
    "# **Load and Preprocess the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1701585799963,
     "user": {
      "displayName": "Rohan Kumar",
      "userId": "17820626819411478205"
     },
     "user_tz": -330
    },
    "id": "JHra-KUuYz30",
    "outputId": "4c1983b4-02e7-463c-cd64-e0df3a8b88b7"
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "train = pd.read_csv(r\"C:\\Users\\Mukaidziwa M\\Desktop\\ALX-DS\\Unsupervised Learning\\Week 4\\Recommender Systems\\ALX Movie Recommendation Project 2024\\train.csv\\train.csv\")\n",
    "test = pd.read_csv(r\"C:\\Users\\Mukaidziwa M\\Desktop\\ALX-DS\\Unsupervised Learning\\Week 4\\Recommender Systems\\ALX Movie Recommendation Project 2024\\test.csv\\test.csv\")\n",
    "movies = pd.read_csv(r\"C:\\Users\\Mukaidziwa M\\Desktop\\ALX-DS\\Unsupervised Learning\\Week 4\\Recommender Systems\\ALX Movie Recommendation Project 2024\\movies.csv\\movies.csv\")\n",
    "\n",
    "# Merge the training data with the movies data to include genres information for each movie\n",
    "df = pd.merge(train, movies[['movieId', 'genres']], on = 'movieId', how = 'left')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1701586189830,
     "user": {
      "displayName": "Rohan Kumar",
      "userId": "17820626819411478205"
     },
     "user_tz": -330
    },
    "id": "kHl4O3SxbAd3"
   },
   "outputs": [],
   "source": [
    "# Initialize LabelEncoders for encoding user and movie IDs\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "\n",
    "# Initialize MultiLabelBinarizer for encoding movie genres into binary format\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Encode the userId and movieId columns using the respective LabelEncoders\n",
    "df['userId'] = user_encoder.fit_transform(df['userId'])\n",
    "df['movieId'] = movie_encoder.fit_transform(df['movieId'])\n",
    "\n",
    "# Split the genres column into separate genre tags, encode them using MultiLabelBinarizer, \n",
    "# and join the resulting binary genre indicators back to the original dataframe\n",
    "df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('genres').str.split('|')), columns = mlb.classes_, index = df.index ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1701586230532,
     "user": {
      "displayName": "Rohan Kumar",
      "userId": "17820626819411478205"
     },
     "user_tz": -330
    },
    "id": "VYK77IxMcKKs",
    "outputId": "44696a2d-37b7-4692-e7ef-2218e99dfaa5"
   },
   "outputs": [],
   "source": [
    "# Drop the column representing movies with no genres listed from the dataframe\n",
    "df.drop(columns = \"(no genres listed)\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 10,000,000 rows from the dataframe for analysis or model training\n",
    "sampled_df = df.sample(n=10000000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zkv99XJgSi0G"
   },
   "source": [
    "# **Build the Model with Collabrative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 955,
     "status": "ok",
     "timestamp": 1701586528088,
     "user": {
      "displayName": "Rohan Kumar",
      "userId": "17820626819411478205"
     },
     "user_tz": -330
    },
    "id": "o1ARM3JRStwQ",
    "outputId": "9254df73-5698-4f71-8193-2f0da4bbdab3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define a reader object with the rating scale for the Surprise library\n",
    "reader = Reader(rating_scale = (0.5, 5))\n",
    "\n",
    "# Load the sampled dataframe into a Surprise Dataset object\n",
    "data = Dataset.load_from_df(sampled_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Build the full trainset from the dataset\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize the SVD model and fit it to the training set\n",
    "model_svd = SVD()\n",
    "model_svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predictions on Test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def predicted_rating(df, model_svd, chunk_size=100):\n",
    "    # Create an empty list to store the predictions\n",
    "    preds = []\n",
    "    \n",
    "    # Calculate the number of chunks\n",
    "    num_chunks = (len(df) // chunk_size) + 1\n",
    "    \n",
    "    # Process each chunk separately\n",
    "    for i in range(num_chunks):\n",
    "        # Define the start and end index of the chunk\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = min((i + 1) * chunk_size, len(df))\n",
    "        \n",
    "        # Extract the chunk\n",
    "        chunk = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Create a list of (user, movie) pairs\n",
    "        user_movie_pairs = [(row['userId'], row['movieId'], 0) for _, row in chunk.iterrows()]\n",
    "        \n",
    "        # Get predictions for each user-movie pair in the chunk\n",
    "        chunk_preds = model_svd.test(user_movie_pairs)\n",
    "        \n",
    "        # Extract the estimated ratings and append to the preds list\n",
    "        preds.extend([pred.est for pred in chunk_preds])\n",
    "    \n",
    "    # Combine predictions into a single numpy array\n",
    "    final_preds = np.array(preds)\n",
    "    \n",
    "    # Add the predicted ratings to the DataFrame\n",
    "    df['predicted_rating'] = final_preds\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Predict movies ratings\n",
    "test_final = predicted_rating(test, model_svd, chunk_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final test dataframe\n",
    "test_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Ensure necessary imports\n",
    "import pandas as pd\n",
    "\n",
    "# Create the Id column by combining userId and movieId\n",
    "test_final['userId'] = test_final['userId'].astype(str).str.replace('-', '')\n",
    "test_final['movieId'] = test_final['movieId'].astype(str).str.replace('-', '')\n",
    "\n",
    "test_final['Id'] = test_final['userId'] + '_' + test_final['movieId']\n",
    "\n",
    "# Ensure predicted_rating is a Series of the same length as sampled_test\n",
    "predicted_rating = pd.Series(predicted_rating, index=test_final.index)\n",
    "\n",
    "# Create a DataFrame for submission\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_final['Id'],\n",
    "    'rating': test_final['predicted_rating']\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Print the first few rows to verify\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN/ePA9K5+5y21noaPNoP77",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
